{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Graph neural network implementation with Protein benchmark dataset.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPDpCAldYICjFwUowZblNqq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SushSushmithagowda/ML-101-projects/blob/main/Graph_neural_network_implementation_with_Protein_benchmark_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, I have carried out two implementations of GCNs to classify the PROTEINS benchmark dataset."
      ],
      "metadata": {
        "id": "5AD2IaaRieZ6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Approach 1: GCN with Spektral"
      ],
      "metadata": {
        "id": "G2zMIo2jf2nS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ycpiw7bnN3z1",
        "outputId": "eda1fd1a-3094-4d7c-8b81-909b188d76c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.7.1)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.0.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.19.5)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.7.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.44.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.7.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.24.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.0)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (13.0.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.10.0.2)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (57.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.2.0)\n",
            "Requirement already satisfied: spektral in /usr/local/lib/python3.7/dist-packages (1.0.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from spektral) (1.3.5)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from spektral) (4.2.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from spektral) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from spektral) (4.63.0)\n",
            "Requirement already satisfied: tensorflow>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from spektral) (2.7.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from spektral) (1.4.1)\n",
            "Requirement already satisfied: numpy<1.20 in /usr/local/lib/python3.7/dist-packages (from spektral) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from spektral) (1.0.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from spektral) (2.6.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from spektral) (1.1.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral) (1.44.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral) (3.17.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral) (3.10.0.2)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral) (1.0.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral) (3.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral) (1.1.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral) (1.15.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral) (2.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral) (0.37.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral) (1.14.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral) (0.2.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral) (0.24.0)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral) (0.4.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral) (13.0.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral) (1.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral) (1.6.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral) (2.7.0)\n",
            "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral) (2.7.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral) (2.8.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral) (3.3.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow>=2.1.0->spektral) (1.5.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.1.0->spektral) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.1.0->spektral) (1.8.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.1.0->spektral) (57.4.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.1.0->spektral) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.1.0->spektral) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.1.0->spektral) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.1.0->spektral) (3.3.6)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.1.0->spektral) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.1.0->spektral) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.1.0->spektral) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.1.0->spektral) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.1.0->spektral) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.1.0->spektral) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.1.0->spektral) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->spektral) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->spektral) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->spektral) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->spektral) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.1.0->spektral) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->spektral) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->spektral) (2018.9)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->spektral) (3.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy\n",
        "!pip install tensorflow\n",
        "!pip install spektral\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import spektral"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#reading in the PROTEINS dataset\n",
        "from spektral.datasets import TUDataset\n"
      ],
      "metadata": {
        "id": "KRlKa3BMSMQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Spectral provides the TUDataset class, which contains benchmark datasets for graph classification\n",
        "data = TUDataset('PROTEINS')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmygq3hGSS8W",
        "outputId": "4c1e939c-9c31-4ac3-9508-4dae034dad92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading PROTEINS dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████████████████████████████████| 447k/447k [00:00<00:00, 689kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully loaded PROTEINS.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7b16ChF3SjRW",
        "outputId": "56c56adf-cb73-4eb8-f8d1-62156bb84e92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TUDataset(n_graphs=1113)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Since we want to utilize the Spektral GCN layer, we want to follow the original paper for this method and perform some preprocessing:\n",
        "from spektral.transforms import GCNFilter\n",
        "\n",
        "data.apply(GCNFilter())"
      ],
      "metadata": {
        "id": "R7RUzDZETTkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split our train and test data. This just splits based on the first 80%/second 20% which isn't entirely ideal, so we'll shuffle the data first.\n",
        "import numpy as np\n",
        "np.random.shuffle(data)\n",
        "split = int(0.8 * len(data))\n",
        "data_train, data_test = data[:split], data[split:]"
      ],
      "metadata": {
        "id": "VrxX1TSxTeyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Spektral is built on top of Keras, so we can use the Keras functional API to build a model that first embeds,\n",
        "# then sums the nodes together (global pooling), then classifies the result with a dense softmax layer\n",
        "\n",
        "# First, let's import the necessary layers:\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from spektral.layers import GCNConv, GlobalSumPool"
      ],
      "metadata": {
        "id": "Won2V6nZTweL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, we can use model subclassing to define our model:\n",
        "class ProteinsGNN(Model):\n",
        "\n",
        "  def __init__(self, n_hidden, n_labels):\n",
        "    super().__init__()\n",
        "    # Define our GCN layer with our n_hidden layers\n",
        "    self.graph_conv = GCNConv(n_hidden)\n",
        "    # Define our global pooling layer\n",
        "    self.pool = GlobalSumPool()\n",
        "    # Define our dropout layer, initialize dropout freq. to .5 (50%)\n",
        "    self.dropout = Dropout(0.5)\n",
        "    # Define our Dense layer, with softmax activation function\n",
        "    self.dense = Dense(n_labels, 'softmax')\n",
        "\n",
        "# Define class method to call model on input\n",
        "  def call(self, inputs):\n",
        "    out = self.graph_conv(inputs)\n",
        "    out = self.dropout(out)\n",
        "    out = self.pool(out)\n",
        "    out = self.dense(out)\n",
        "\n",
        "    return out"
      ],
      "metadata": {
        "id": "9e-R3pcnUBSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate our model for training\n",
        "model = ProteinsGNN(32, data.n_labels)"
      ],
      "metadata": {
        "id": "bK_DYT7_UjXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile model with our optimizer (adam) and loss function\n",
        "model.compile('adam', 'categorical_crossentropy')"
      ],
      "metadata": {
        "id": "Sx6QCUs1UmTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Here's the trick - we can't just call Keras' fit() method on this model.\n",
        "# Instead, we have to use Loaders, which Spektral walks us through. Loaders create mini-batches by iterating over the graph\n",
        "# Since we're using Spektral for an experiment, for our first trial we'll use the recommended loader in the getting started tutorial\n",
        "\n",
        "# TODO: read up on modes and try other loaders later\n",
        "from spektral.data import BatchLoader\n",
        "\n",
        "loader = BatchLoader(data_train, batch_size=32)"
      ],
      "metadata": {
        "id": "egKixQe7UpII"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we can train! We don't need to specify a batch size, since our loader is basically a generator\n",
        "# But we do need to specify the steps_per_epoch parameter\n",
        "\n",
        "model.fit(loader.load(), steps_per_epoch=loader.steps_per_epoch, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zP7a5dwHUvGy",
        "outputId": "81d3888b-9284-41bb-a169-08b6d8e07a4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "28/28 [==============================] - 5s 55ms/step - loss: 29.2422\n",
            "Epoch 2/10\n",
            "28/28 [==============================] - 1s 35ms/step - loss: 9.5231\n",
            "Epoch 3/10\n",
            "28/28 [==============================] - 1s 31ms/step - loss: 6.4763\n",
            "Epoch 4/10\n",
            "28/28 [==============================] - 1s 28ms/step - loss: 6.9496\n",
            "Epoch 5/10\n",
            "28/28 [==============================] - 1s 27ms/step - loss: 6.8298\n",
            "Epoch 6/10\n",
            "28/28 [==============================] - 1s 25ms/step - loss: 5.6849\n",
            "Epoch 7/10\n",
            "28/28 [==============================] - 1s 24ms/step - loss: 5.5387\n",
            "Epoch 8/10\n",
            "28/28 [==============================] - 1s 28ms/step - loss: 6.2545\n",
            "Epoch 9/10\n",
            "28/28 [==============================] - 1s 25ms/step - loss: 5.1228\n",
            "Epoch 10/10\n",
            "28/28 [==============================] - 1s 28ms/step - loss: 6.0772\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd14f938250>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To evaluate, let's instantiate another loader to test\n",
        "\n",
        "test_loader = BatchLoader(data_test, batch_size=32)"
      ],
      "metadata": {
        "id": "oE0NasXTVOQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# And feed it to our model by calling .load()\n",
        "\n",
        "loss = model.evaluate(loader.load(), steps=loader.steps_per_epoch)\n",
        "\n",
        "print('Test loss: {}'.format(loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dh6EcbzSVPdd",
        "outputId": "9b1eb7ae-d22d-4678-ba80-567fac8596cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "28/28 [==============================] - 1s 21ms/step - loss: 3.8005\n",
            "Test loss: 3.8004508018493652\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This concludes building GCN's with Spektral."
      ],
      "metadata": {
        "id": "rc_u6xTEi_fp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Approach - 2\n",
        "GCN's with Pytorch-Geometric"
      ],
      "metadata": {
        "id": "pXND2kjeVp7p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages.\n",
        "!pip install -q torch-scatter -f https://pytorch-geometric.com/whl/torch-1.8.0+cu101.html\n",
        "!pip install -q torch-sparse -f https://pytorch-geometric.com/whl/torch-1.8.0+cu101.html\n",
        "!pip install -q torch-geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OCNw8SuVpMf",
        "outputId": "b602cdc2-544f-4586-cd81-a50bfe8640dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 48 kB 3.3 MB/s \n",
            "\u001b[?25h  Building wheel for torch-sparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 407 kB 8.4 MB/s \n",
            "\u001b[?25h  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch_geometric.datasets import TUDataset\n",
        "\n",
        "# Like Spektral, pytorch geometric provides us with benchmark TUDatasets\n",
        "dataset = TUDataset(root='data/TUDataset', name='PROTEINS')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwoYOeuUY7Oj",
        "outputId": "931e349f-cc0d-4bb1-e89f-65e7c428a4fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://www.chrsmrrs.com/graphkerneldatasets/PROTEINS.zip\n",
            "Extracting data/TUDataset/PROTEINS/PROTEINS.zip\n",
            "Processing...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's take a look at our data. We'll look at dataset (all data) and data (our first graph):\n",
        "\n",
        "data = dataset[0]  # Get the first graph object.\n",
        "\n",
        "print()\n",
        "print(f'Dataset: {dataset}:')\n",
        "print('====================')\n",
        "# How many graphs?\n",
        "print(f'Number of graphs: {len(dataset)}')\n",
        "# How many features?\n",
        "print(f'Number of features: {dataset.num_features}')\n",
        "# Now, in our first graph, how many edges?\n",
        "print(f'Number of edges: {data.num_edges}')\n",
        "# Average node degree?\n",
        "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
        "# Do we have isolated nodes?\n",
        "print(f'Contains isolated nodes: {data.contains_isolated_nodes()}')\n",
        "# Do we contain self-loops?\n",
        "print(f'Contains self-loops: {data.contains_self_loops()}')\n",
        "# Is this an undirected graph?\n",
        "print(f'Is undirected: {data.is_undirected()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aw8yO61sZCjq",
        "outputId": "f312ebca-5f7f-46cf-cc68-46c036b0eeb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset: PROTEINS(1113):\n",
            "====================\n",
            "Number of graphs: 1113\n",
            "Number of features: 3\n",
            "Number of edges: 162\n",
            "Average node degree: 3.86\n",
            "Contains isolated nodes: False\n",
            "Contains self-loops: False\n",
            "Is undirected: True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch_geometric/deprecation.py:12: UserWarning: 'contains_isolated_nodes' is deprecated, use 'has_isolated_nodes' instead\n",
            "  warnings.warn(out)\n",
            "/usr/local/lib/python3.7/dist-packages/torch_geometric/deprecation.py:12: UserWarning: 'contains_self_loops' is deprecated, use 'has_self_loops' instead\n",
            "  warnings.warn(out)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, we need to perform our train/test split.\n",
        "# We create a seed, and then shuffle our data\n",
        "torch.manual_seed(12345)\n",
        "dataset = dataset.shuffle()\n",
        "\n",
        "# Once it's shuffled, we slice the data to split\n",
        "train_dataset = dataset[150:-150]\n",
        "test_dataset = dataset[0:150]\n",
        "\n",
        "# Take a look at the training versus test graphs\n",
        "print(f'Number of training graphs: {len(train_dataset)}')\n",
        "print(f'Number of test graphs: {len(test_dataset)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1Nqp_LfZIJv",
        "outputId": "0dc6bf47-014f-4082-b076-f7a27f065f4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training graphs: 813\n",
            "Number of test graphs: 150\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import DataLoader for batching\n",
        "from torch_geometric.data import DataLoader\n",
        "\n",
        "# our DataLoader creates diagonal adjacency matrices, and concatenates features\n",
        "# and target matrices in the node dimension. This allows differing numbers of nodes and edges \n",
        "# over examples in one batch. (from pytorch geometric docs)\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OkcQ9GLJZMmj",
        "outputId": "456a9eea-30dd-4ec3-ce16-8f8a128db375"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch_geometric/deprecation.py:12: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import everything we need to build our network:\n",
        "from torch.nn import Linear\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.nn import global_mean_pool\n",
        "\n",
        "# Define our GCN class as a pytorch Module\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super(GCN, self).__init__()\n",
        "        # We inherit from pytorch geometric's GCN class, and we initialize three layers\n",
        "        self.conv1 = GCNConv(dataset.num_node_features, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
        "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
        "        # Our final linear layer will define our output\n",
        "        self.lin = Linear(hidden_channels, dataset.num_classes)\n",
        "        \n",
        "    def forward(self, x, edge_index, batch):\n",
        "      # 1. Obtain node embeddings \n",
        "      x = self.conv1(x, edge_index)\n",
        "      x = x.relu()\n",
        "      x = self.conv2(x, edge_index)\n",
        "      x = x.relu()\n",
        "      x = self.conv3(x, edge_index)\n",
        "      \n",
        "      # 2. Readout layer\n",
        "      x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n",
        "\n",
        "      # 3. Apply a final classifier\n",
        "      x = F.dropout(x, p=0.5, training=self.training)\n",
        "      x = self.lin(x)\n",
        "      return x\n",
        "    \n",
        "model = GCN(hidden_channels=64)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-gNL-HHZScK",
        "outputId": "2cb3cc95-5328-4ba7-b726-ecf412d7e239"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GCN(\n",
            "  (conv1): GCNConv(3, 64)\n",
            "  (conv2): GCNConv(64, 64)\n",
            "  (conv3): GCNConv(64, 64)\n",
            "  (lin): Linear(in_features=64, out_features=2, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set our optimizer (adam)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "# Define our loss function\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Initialize our train function\n",
        "def train():\n",
        "    model.train()\n",
        "\n",
        "    for data in train_loader:  # Iterate in batches over the training dataset.\n",
        "      out = model(data.x, data.edge_index, data.batch)  # Perform a single forward pass.\n",
        "      loss = criterion(out, data.y)  # Compute the loss.\n",
        "      loss.backward()  # Derive gradients.\n",
        "      optimizer.step()  # Update parameters based on gradients.\n",
        "      optimizer.zero_grad()  # Clear gradients.\n",
        "      \n",
        "# Define our test function\n",
        "def test(loader):\n",
        "  model.eval()\n",
        "\n",
        "  correct = 0\n",
        "  for data in loader:  # Iterate in batches over the training/test dataset.\n",
        "      out = model(data.x, data.edge_index, data.batch)  \n",
        "      pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
        "      correct += int((pred == data.y).sum())  # Check against ground-truth labels.\n",
        "  return correct / len(loader.dataset)  # Derive ratio of correct predictions.\n",
        "\n",
        "\n",
        "# Run for 200 epochs (range is exclusive in the upper bound)\n",
        "for epoch in range(1, 201):\n",
        "    train()\n",
        "    train_acc = test(train_loader)\n",
        "    test_acc = test(test_loader)\n",
        "    print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "muL54PjRZbTK",
        "outputId": "18de646c-096a-4a95-bf1d-b6fa3a353734"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 001, Train Acc: 0.6335, Test Acc: 0.6267\n",
            "Epoch: 002, Train Acc: 0.6248, Test Acc: 0.6867\n",
            "Epoch: 003, Train Acc: 0.6347, Test Acc: 0.6267\n",
            "Epoch: 004, Train Acc: 0.6494, Test Acc: 0.6800\n",
            "Epoch: 005, Train Acc: 0.6913, Test Acc: 0.7467\n",
            "Epoch: 006, Train Acc: 0.6802, Test Acc: 0.7333\n",
            "Epoch: 007, Train Acc: 0.7109, Test Acc: 0.7200\n",
            "Epoch: 008, Train Acc: 0.7146, Test Acc: 0.7267\n",
            "Epoch: 009, Train Acc: 0.6827, Test Acc: 0.7133\n",
            "Epoch: 010, Train Acc: 0.6753, Test Acc: 0.6667\n",
            "Epoch: 011, Train Acc: 0.6421, Test Acc: 0.6267\n",
            "Epoch: 012, Train Acc: 0.6667, Test Acc: 0.6467\n",
            "Epoch: 013, Train Acc: 0.6642, Test Acc: 0.6933\n",
            "Epoch: 014, Train Acc: 0.6986, Test Acc: 0.7067\n",
            "Epoch: 015, Train Acc: 0.7220, Test Acc: 0.7267\n",
            "Epoch: 016, Train Acc: 0.6581, Test Acc: 0.7067\n",
            "Epoch: 017, Train Acc: 0.6814, Test Acc: 0.7067\n",
            "Epoch: 018, Train Acc: 0.6716, Test Acc: 0.6867\n",
            "Epoch: 019, Train Acc: 0.6679, Test Acc: 0.6667\n",
            "Epoch: 020, Train Acc: 0.6851, Test Acc: 0.6867\n",
            "Epoch: 021, Train Acc: 0.7159, Test Acc: 0.7200\n",
            "Epoch: 022, Train Acc: 0.7048, Test Acc: 0.7267\n",
            "Epoch: 023, Train Acc: 0.6740, Test Acc: 0.6600\n",
            "Epoch: 024, Train Acc: 0.6925, Test Acc: 0.6933\n",
            "Epoch: 025, Train Acc: 0.6925, Test Acc: 0.7200\n",
            "Epoch: 026, Train Acc: 0.7036, Test Acc: 0.7067\n",
            "Epoch: 027, Train Acc: 0.6790, Test Acc: 0.6800\n",
            "Epoch: 028, Train Acc: 0.6765, Test Acc: 0.7067\n",
            "Epoch: 029, Train Acc: 0.6986, Test Acc: 0.7200\n",
            "Epoch: 030, Train Acc: 0.6814, Test Acc: 0.7267\n",
            "Epoch: 031, Train Acc: 0.6827, Test Acc: 0.7133\n",
            "Epoch: 032, Train Acc: 0.6790, Test Acc: 0.6533\n",
            "Epoch: 033, Train Acc: 0.7146, Test Acc: 0.7333\n",
            "Epoch: 034, Train Acc: 0.7085, Test Acc: 0.7133\n",
            "Epoch: 035, Train Acc: 0.7122, Test Acc: 0.7267\n",
            "Epoch: 036, Train Acc: 0.7183, Test Acc: 0.7333\n",
            "Epoch: 037, Train Acc: 0.6876, Test Acc: 0.7200\n",
            "Epoch: 038, Train Acc: 0.6863, Test Acc: 0.6600\n",
            "Epoch: 039, Train Acc: 0.6716, Test Acc: 0.6933\n",
            "Epoch: 040, Train Acc: 0.7109, Test Acc: 0.7267\n",
            "Epoch: 041, Train Acc: 0.6986, Test Acc: 0.7067\n",
            "Epoch: 042, Train Acc: 0.6593, Test Acc: 0.7067\n",
            "Epoch: 043, Train Acc: 0.6937, Test Acc: 0.7000\n",
            "Epoch: 044, Train Acc: 0.7245, Test Acc: 0.7333\n",
            "Epoch: 045, Train Acc: 0.7036, Test Acc: 0.7200\n",
            "Epoch: 046, Train Acc: 0.7220, Test Acc: 0.7267\n",
            "Epoch: 047, Train Acc: 0.7134, Test Acc: 0.7200\n",
            "Epoch: 048, Train Acc: 0.6999, Test Acc: 0.7133\n",
            "Epoch: 049, Train Acc: 0.7011, Test Acc: 0.7200\n",
            "Epoch: 050, Train Acc: 0.7097, Test Acc: 0.7400\n",
            "Epoch: 051, Train Acc: 0.7257, Test Acc: 0.7200\n",
            "Epoch: 052, Train Acc: 0.7171, Test Acc: 0.7267\n",
            "Epoch: 053, Train Acc: 0.6974, Test Acc: 0.7333\n",
            "Epoch: 054, Train Acc: 0.7183, Test Acc: 0.7467\n",
            "Epoch: 055, Train Acc: 0.7060, Test Acc: 0.7400\n",
            "Epoch: 056, Train Acc: 0.6716, Test Acc: 0.6933\n",
            "Epoch: 057, Train Acc: 0.7208, Test Acc: 0.7333\n",
            "Epoch: 058, Train Acc: 0.6962, Test Acc: 0.7133\n",
            "Epoch: 059, Train Acc: 0.6851, Test Acc: 0.7133\n",
            "Epoch: 060, Train Acc: 0.7171, Test Acc: 0.7267\n",
            "Epoch: 061, Train Acc: 0.7085, Test Acc: 0.7000\n",
            "Epoch: 062, Train Acc: 0.7109, Test Acc: 0.7467\n",
            "Epoch: 063, Train Acc: 0.7159, Test Acc: 0.7400\n",
            "Epoch: 064, Train Acc: 0.7220, Test Acc: 0.7333\n",
            "Epoch: 065, Train Acc: 0.7269, Test Acc: 0.7533\n",
            "Epoch: 066, Train Acc: 0.6544, Test Acc: 0.6467\n",
            "Epoch: 067, Train Acc: 0.6974, Test Acc: 0.7133\n",
            "Epoch: 068, Train Acc: 0.6876, Test Acc: 0.7267\n",
            "Epoch: 069, Train Acc: 0.6876, Test Acc: 0.7067\n",
            "Epoch: 070, Train Acc: 0.7196, Test Acc: 0.7467\n",
            "Epoch: 071, Train Acc: 0.6777, Test Acc: 0.6933\n",
            "Epoch: 072, Train Acc: 0.7122, Test Acc: 0.7400\n",
            "Epoch: 073, Train Acc: 0.7232, Test Acc: 0.7200\n",
            "Epoch: 074, Train Acc: 0.6777, Test Acc: 0.6600\n",
            "Epoch: 075, Train Acc: 0.6950, Test Acc: 0.7267\n",
            "Epoch: 076, Train Acc: 0.6765, Test Acc: 0.6867\n",
            "Epoch: 077, Train Acc: 0.7060, Test Acc: 0.7400\n",
            "Epoch: 078, Train Acc: 0.6667, Test Acc: 0.7133\n",
            "Epoch: 079, Train Acc: 0.7171, Test Acc: 0.7333\n",
            "Epoch: 080, Train Acc: 0.7220, Test Acc: 0.7267\n",
            "Epoch: 081, Train Acc: 0.7183, Test Acc: 0.7200\n",
            "Epoch: 082, Train Acc: 0.6913, Test Acc: 0.7400\n",
            "Epoch: 083, Train Acc: 0.6802, Test Acc: 0.7267\n",
            "Epoch: 084, Train Acc: 0.6999, Test Acc: 0.7067\n",
            "Epoch: 085, Train Acc: 0.6839, Test Acc: 0.6533\n",
            "Epoch: 086, Train Acc: 0.7257, Test Acc: 0.7467\n",
            "Epoch: 087, Train Acc: 0.6839, Test Acc: 0.7200\n",
            "Epoch: 088, Train Acc: 0.7220, Test Acc: 0.7200\n",
            "Epoch: 089, Train Acc: 0.6716, Test Acc: 0.6400\n",
            "Epoch: 090, Train Acc: 0.7060, Test Acc: 0.7067\n",
            "Epoch: 091, Train Acc: 0.7196, Test Acc: 0.7267\n",
            "Epoch: 092, Train Acc: 0.7159, Test Acc: 0.7333\n",
            "Epoch: 093, Train Acc: 0.7146, Test Acc: 0.7267\n",
            "Epoch: 094, Train Acc: 0.7183, Test Acc: 0.7467\n",
            "Epoch: 095, Train Acc: 0.7122, Test Acc: 0.7200\n",
            "Epoch: 096, Train Acc: 0.6679, Test Acc: 0.7267\n",
            "Epoch: 097, Train Acc: 0.6740, Test Acc: 0.6933\n",
            "Epoch: 098, Train Acc: 0.6851, Test Acc: 0.6533\n",
            "Epoch: 099, Train Acc: 0.7134, Test Acc: 0.7200\n",
            "Epoch: 100, Train Acc: 0.7036, Test Acc: 0.7333\n",
            "Epoch: 101, Train Acc: 0.6937, Test Acc: 0.6733\n",
            "Epoch: 102, Train Acc: 0.7171, Test Acc: 0.7267\n",
            "Epoch: 103, Train Acc: 0.7060, Test Acc: 0.7000\n",
            "Epoch: 104, Train Acc: 0.7220, Test Acc: 0.7267\n",
            "Epoch: 105, Train Acc: 0.7183, Test Acc: 0.7133\n",
            "Epoch: 106, Train Acc: 0.7122, Test Acc: 0.7067\n",
            "Epoch: 107, Train Acc: 0.6999, Test Acc: 0.7200\n",
            "Epoch: 108, Train Acc: 0.6950, Test Acc: 0.7067\n",
            "Epoch: 109, Train Acc: 0.7097, Test Acc: 0.7333\n",
            "Epoch: 110, Train Acc: 0.7023, Test Acc: 0.7000\n",
            "Epoch: 111, Train Acc: 0.6827, Test Acc: 0.7067\n",
            "Epoch: 112, Train Acc: 0.6913, Test Acc: 0.7000\n",
            "Epoch: 113, Train Acc: 0.7257, Test Acc: 0.7200\n",
            "Epoch: 114, Train Acc: 0.7073, Test Acc: 0.7333\n",
            "Epoch: 115, Train Acc: 0.7232, Test Acc: 0.7267\n",
            "Epoch: 116, Train Acc: 0.7122, Test Acc: 0.7533\n",
            "Epoch: 117, Train Acc: 0.7122, Test Acc: 0.7133\n",
            "Epoch: 118, Train Acc: 0.7257, Test Acc: 0.7467\n",
            "Epoch: 119, Train Acc: 0.7146, Test Acc: 0.7133\n",
            "Epoch: 120, Train Acc: 0.7343, Test Acc: 0.7333\n",
            "Epoch: 121, Train Acc: 0.7159, Test Acc: 0.7133\n",
            "Epoch: 122, Train Acc: 0.7220, Test Acc: 0.7267\n",
            "Epoch: 123, Train Acc: 0.7245, Test Acc: 0.7267\n",
            "Epoch: 124, Train Acc: 0.7208, Test Acc: 0.7267\n",
            "Epoch: 125, Train Acc: 0.7122, Test Acc: 0.7200\n",
            "Epoch: 126, Train Acc: 0.7196, Test Acc: 0.7067\n",
            "Epoch: 127, Train Acc: 0.6777, Test Acc: 0.7400\n",
            "Epoch: 128, Train Acc: 0.7171, Test Acc: 0.7267\n",
            "Epoch: 129, Train Acc: 0.6728, Test Acc: 0.7333\n",
            "Epoch: 130, Train Acc: 0.5941, Test Acc: 0.6067\n",
            "Epoch: 131, Train Acc: 0.6827, Test Acc: 0.6800\n",
            "Epoch: 132, Train Acc: 0.6802, Test Acc: 0.6533\n",
            "Epoch: 133, Train Acc: 0.6851, Test Acc: 0.6600\n",
            "Epoch: 134, Train Acc: 0.6851, Test Acc: 0.6867\n",
            "Epoch: 135, Train Acc: 0.6814, Test Acc: 0.6667\n",
            "Epoch: 136, Train Acc: 0.7159, Test Acc: 0.7133\n",
            "Epoch: 137, Train Acc: 0.6790, Test Acc: 0.7333\n",
            "Epoch: 138, Train Acc: 0.6827, Test Acc: 0.7000\n",
            "Epoch: 139, Train Acc: 0.6851, Test Acc: 0.6667\n",
            "Epoch: 140, Train Acc: 0.7122, Test Acc: 0.7200\n",
            "Epoch: 141, Train Acc: 0.6814, Test Acc: 0.6800\n",
            "Epoch: 142, Train Acc: 0.6925, Test Acc: 0.7333\n",
            "Epoch: 143, Train Acc: 0.7134, Test Acc: 0.7267\n",
            "Epoch: 144, Train Acc: 0.6716, Test Acc: 0.7333\n",
            "Epoch: 145, Train Acc: 0.7245, Test Acc: 0.7200\n",
            "Epoch: 146, Train Acc: 0.7183, Test Acc: 0.7200\n",
            "Epoch: 147, Train Acc: 0.7257, Test Acc: 0.7267\n",
            "Epoch: 148, Train Acc: 0.7208, Test Acc: 0.7533\n",
            "Epoch: 149, Train Acc: 0.7245, Test Acc: 0.7267\n",
            "Epoch: 150, Train Acc: 0.7196, Test Acc: 0.7400\n",
            "Epoch: 151, Train Acc: 0.7257, Test Acc: 0.7333\n",
            "Epoch: 152, Train Acc: 0.7232, Test Acc: 0.7600\n",
            "Epoch: 153, Train Acc: 0.7171, Test Acc: 0.7133\n",
            "Epoch: 154, Train Acc: 0.7269, Test Acc: 0.7333\n",
            "Epoch: 155, Train Acc: 0.7208, Test Acc: 0.7400\n",
            "Epoch: 156, Train Acc: 0.7232, Test Acc: 0.7200\n",
            "Epoch: 157, Train Acc: 0.6863, Test Acc: 0.6600\n",
            "Epoch: 158, Train Acc: 0.7048, Test Acc: 0.7067\n",
            "Epoch: 159, Train Acc: 0.7036, Test Acc: 0.7467\n",
            "Epoch: 160, Train Acc: 0.7097, Test Acc: 0.7133\n",
            "Epoch: 161, Train Acc: 0.7085, Test Acc: 0.7400\n",
            "Epoch: 162, Train Acc: 0.7282, Test Acc: 0.7200\n",
            "Epoch: 163, Train Acc: 0.6667, Test Acc: 0.7333\n",
            "Epoch: 164, Train Acc: 0.7109, Test Acc: 0.7200\n",
            "Epoch: 165, Train Acc: 0.7269, Test Acc: 0.7133\n",
            "Epoch: 166, Train Acc: 0.7085, Test Acc: 0.7200\n",
            "Epoch: 167, Train Acc: 0.6986, Test Acc: 0.7333\n",
            "Epoch: 168, Train Acc: 0.7269, Test Acc: 0.7333\n",
            "Epoch: 169, Train Acc: 0.7183, Test Acc: 0.7200\n",
            "Epoch: 170, Train Acc: 0.6986, Test Acc: 0.7467\n",
            "Epoch: 171, Train Acc: 0.7196, Test Acc: 0.7067\n",
            "Epoch: 172, Train Acc: 0.7257, Test Acc: 0.7400\n",
            "Epoch: 173, Train Acc: 0.7060, Test Acc: 0.7333\n",
            "Epoch: 174, Train Acc: 0.7220, Test Acc: 0.7467\n",
            "Epoch: 175, Train Acc: 0.7023, Test Acc: 0.7333\n",
            "Epoch: 176, Train Acc: 0.6962, Test Acc: 0.7067\n",
            "Epoch: 177, Train Acc: 0.6839, Test Acc: 0.6600\n",
            "Epoch: 178, Train Acc: 0.7196, Test Acc: 0.7067\n",
            "Epoch: 179, Train Acc: 0.7060, Test Acc: 0.7333\n",
            "Epoch: 180, Train Acc: 0.7196, Test Acc: 0.7267\n",
            "Epoch: 181, Train Acc: 0.7196, Test Acc: 0.7200\n",
            "Epoch: 182, Train Acc: 0.7060, Test Acc: 0.7333\n",
            "Epoch: 183, Train Acc: 0.7196, Test Acc: 0.7400\n",
            "Epoch: 184, Train Acc: 0.6974, Test Acc: 0.6867\n",
            "Epoch: 185, Train Acc: 0.7196, Test Acc: 0.7533\n",
            "Epoch: 186, Train Acc: 0.7109, Test Acc: 0.7333\n",
            "Epoch: 187, Train Acc: 0.7232, Test Acc: 0.7333\n",
            "Epoch: 188, Train Acc: 0.7171, Test Acc: 0.7467\n",
            "Epoch: 189, Train Acc: 0.6790, Test Acc: 0.7333\n",
            "Epoch: 190, Train Acc: 0.6962, Test Acc: 0.7600\n",
            "Epoch: 191, Train Acc: 0.7196, Test Acc: 0.7267\n",
            "Epoch: 192, Train Acc: 0.6839, Test Acc: 0.7400\n",
            "Epoch: 193, Train Acc: 0.7208, Test Acc: 0.7133\n",
            "Epoch: 194, Train Acc: 0.6937, Test Acc: 0.7267\n",
            "Epoch: 195, Train Acc: 0.7011, Test Acc: 0.7467\n",
            "Epoch: 196, Train Acc: 0.7183, Test Acc: 0.7267\n",
            "Epoch: 197, Train Acc: 0.7159, Test Acc: 0.7067\n",
            "Epoch: 198, Train Acc: 0.7257, Test Acc: 0.7333\n",
            "Epoch: 199, Train Acc: 0.7245, Test Acc: 0.7133\n",
            "Epoch: 200, Train Acc: 0.7036, Test Acc: 0.7600\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looking at the last 20 epochs, the model seems to have achieved 70% training accuracy and about 76% testing accuracy. This infers the model being able to predict good results having low bias without inclining towards 'overfitting','underfitting' pitfall.   "
      ],
      "metadata": {
        "id": "HB5ZsPG5jLJl"
      }
    }
  ]
}